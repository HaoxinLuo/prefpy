{
 "metadata": {
  "name": "CompSoc Project"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from scipy import stats\n",
      "import time\n",
      "import heapq\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def interpret_rank_data(filename):\n",
      "    \"\"\"Takes name for text file with data in form NAMES\\n TYPES\\n DATA with D dimensions and L labels.\n",
      "       Returns data in the form [(x_1..x_D)],[(l_1..l_L)]\"\"\"\n",
      "    X = []\n",
      "    L = []\n",
      "    datafile = open(filename, 'r')\n",
      "    header = datafile.readline().split('\\t') # Get first line, split\n",
      "    header[-1] = header[-1].rstrip() # Get rid of trailing newline\n",
      "    ndim = 0\n",
      "    nlab = 0\n",
      "    for elt in header:\n",
      "        if elt[0] == 'L':\n",
      "            nlab += 1\n",
      "        if elt[0] == 'A':\n",
      "            ndim += 1\n",
      "    datafile.readline() # Skip the next line, it's really not necessary\n",
      "    raw_data = datafile.readlines()  \n",
      "    for line in raw_data:\n",
      "        thisX = []\n",
      "        thisL = []\n",
      "        if line[0] == '\\r': # TODO: Make this more graceful\n",
      "            continue\n",
      "        line = line.rstrip().split('\\t')\n",
      "        for i in range(ndim):\n",
      "            thisX.append(float(line[i]))\n",
      "        for i in range(nlab):\n",
      "            thisL.append(int(line[i+ndim]))\n",
      "        X.append(thisX)\n",
      "        L.append(thisL)\n",
      "    datafile.close()\n",
      "    return np.array(X), L"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, L = interpret_rank_data('LabelRankingData/iris_dense.txt')\n",
      "print np.sqrt(X.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12.2474487139\n"
       ]
      }
     ],
     "prompt_number": 310
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class IB_PLGMM:\n",
      "    def __init__(self, breaking='full', K=0, weighting=lambda x: 1, useborda=False, k=3):\n",
      "        \"\"\" Initialize, taking breaking as option \"\"\"\n",
      "        self.breaking = breaking\n",
      "        self.K = K\n",
      "        self.k = k\n",
      "        self.weighting = weighting\n",
      "        self.useborda = useborda\n",
      "    \n",
      "    def train(self, X, L):\n",
      "        \"\"\" \"Train\" the model by loading the data and setting k, m\"\"\"\n",
      "        # This pretty much constitutes training\n",
      "        self.X = X\n",
      "        self.L = L\n",
      "        self.dataset = zip(self.X, self.L)\n",
      "        #self.k = int(np.sqrt(X.shape[0]))\n",
      "        self.m = len(L[0])\n",
      "        \n",
      "    def _row_in(self, point):\n",
      "        for i in self.dataset:\n",
      "            if all(np.abs(i[0] - point) < 1e-9):\n",
      "                print \"Found eerily similar point:\", i, point\n",
      "                return True\n",
      "        return False\n",
      "   \n",
      "    def _get_k_nearest(self, k, point):\n",
      "        \"\"\" Get k nearest neighbors of a point O(nlogk + klogk)\"\"\"\n",
      "        #self._row_in(point)\n",
      "        dist = lambda x: np.linalg.norm(point - x[0]) # Assuming a zip will be given\n",
      "        init_heap = [(dist(i), i) for i in self.dataset[:k]]\n",
      "        for instance in self.dataset:\n",
      "            cur_dist = dist(instance)\n",
      "            if cur_dist < init_heap[0][0]:\n",
      "                try:\n",
      "                    heapq.heappop(init_heap)\n",
      "                except ValueError:\n",
      "                    print init_heap[0]\n",
      "                try:\n",
      "                    heapq.heappush(init_heap, (cur_dist, instance))\n",
      "                except ValueError:\n",
      "                    print (cur_dist, instance)\n",
      "        return [i[1] for i in sorted(init_heap, key=lambda x: x[0])]\n",
      "    \n",
      "    def _full(self, k):\n",
      "        \"\"\" Full breaking \"\"\"\n",
      "        # doesn't do anything with k\n",
      "        G = np.ones((self.m, self.m))\n",
      "        np.fill_diagonal(G, 0)\n",
      "        return G\n",
      "    \n",
      "    def _top(self, k):\n",
      "        \"\"\" Top k breaking \"\"\"\n",
      "        if k > self.m:\n",
      "            raise ValueError\n",
      "        G = np.ones((self.m, self.m))\n",
      "        np.fill_diagonal(G, 0)\n",
      "        for i in range(self.m):\n",
      "            for j in range(self.m):\n",
      "                if i == j:\n",
      "                    continue\n",
      "                if i > k and j > k:\n",
      "                    G[i][j] = 0\n",
      "        return G\n",
      "    \n",
      "    def _bot(self, k):\n",
      "        \"\"\" Bottom k breaking \"\"\"\n",
      "        if k < 2:\n",
      "            raise ValueError\n",
      "        G = np.ones((self.m, self.m))\n",
      "        np.fill_diagonal(G, 0)\n",
      "        for i in range(self.m):\n",
      "            for j in range(self.m):\n",
      "                if i == j:\n",
      "                    continue\n",
      "                if i <= k and j <= k:\n",
      "                    G[i][j] = 0\n",
      "        return G\n",
      "    \n",
      "    def _adj(self, k):\n",
      "        \"\"\" Adjacent breaking \"\"\"\n",
      "        # doesn't do anything with k\n",
      "        G = np.zeros((self.m, self.m))\n",
      "        for i in range(self.m):\n",
      "            for j in range(self.m):\n",
      "                if (i == j+1) or (j == i+1):\n",
      "                    G[i][j] = 1\n",
      "        return G\n",
      "    \n",
      "    def _pos(self, k):\n",
      "        \"\"\" Position k breaking \"\"\"\n",
      "        if k < 2:\n",
      "            raise ValueError\n",
      "        G = np.zeros((self.m, self.m))\n",
      "        for i in range(self.m):\n",
      "            for j in range(self.m):\n",
      "                if i == j:\n",
      "                    continue\n",
      "                if i < k or j < k:\n",
      "                    continue\n",
      "                if i == k or j == k:\n",
      "                    G[i][j] = 1\n",
      "        return G\n",
      "    \n",
      "    def _get_GMM(self, neighbors, point):\n",
      "        \"\"\" Given all of the neighbors in the form [(X, L)], get the GMM estimate of the parameters\n",
      "            Can take breakings as defined in Lirong's paper \"\"\"\n",
      "        breakings = {\n",
      "            'full':self._full,\n",
      "            'top':self._top,\n",
      "            'botk':self._bot,\n",
      "            'adj':self._adj,\n",
      "            'posk':self._pos\n",
      "        }\n",
      "        # Get a breaking\n",
      "        breaking_adjmat = breakings[self.breaking](self.K)\n",
      "        P = np.zeros((self.m, self.m))\n",
      "        # Compute list of distances\n",
      "        dist = lambda x: np.linalg.norm(point - x)\n",
      "        distance_list = np.array([dist(i[0]) for i in neighbors])\n",
      "        max_dist = max(distance_list)\n",
      "        # Normalize it to [0,1]\n",
      "        distance_list /= max_dist\n",
      "        \n",
      "        for ind, neighbor in enumerate(neighbors):\n",
      "            # First get ranking matrix X (rm for scope reasons)\n",
      "            rm = np.zeros((self.m, self.m))\n",
      "            for i in range(self.m):\n",
      "                for j in range(self.m):\n",
      "                    alt_i_pos = neighbor[1].index(i+1) # silliness with 1-indexing of alternatives\n",
      "                    alt_j_pos = neighbor[1].index(j+1)\n",
      "                    if alt_i_pos < alt_j_pos: # i.e., alt_i > alt_j in the ranking since indices are backwards\n",
      "                        rm[i][j] = 1\n",
      "            rm *= breaking_adjmat # Essentially AND it with the adjacency matrix representing the breaking\n",
      "            # Construct local P from rm\n",
      "            localP = rm[:]\n",
      "            # Essentially compute the values in the diagonal, and fill it\n",
      "            for i in range(self.m):\n",
      "                localP[i][i] = -1*(np.sum(rm.T[i][:i]) + np.sum(rm.T[i][i+1:])) # quick and dirty way to do sum w/o i\n",
      "            # Before we can weight it by distance, we need to get\n",
      "            # Now weight it. Works as 1/weighting\n",
      "            localP *= self.weighting(distance_list[ind])/float(len(neighbors))\n",
      "            P += localP\n",
      "        # Now that we have P_G(D), we can solve the system P_G(D)*gamma = 0 with an svd of P_G(D)\n",
      "        epsilon = 1e-7 # Close enough to 0 for 32bit precision\n",
      "        #print P\n",
      "        #try:\n",
      "        #    assert(np.linalg.matrix_rank(P) == self.m-1)\n",
      "        #except AssertionError:\n",
      "        #    print np.linalg.matrix_rank(P), self.m, P\n",
      "        #    raise\n",
      "        try:\n",
      "            assert(all(np.sum(P, axis=0) <= epsilon))\n",
      "        except AssertionError:\n",
      "            print np.sum(P, axis=0)\n",
      "            raise\n",
      "        U, S, V = np.linalg.svd(P)\n",
      "        # Found on stackoverflow\n",
      "        gamma = np.abs(np.compress(S <= epsilon, V, axis=0).T)\n",
      "        # John's method, since rank is supposedly m-1\n",
      "        #gamma = np.abs(V[-1])\n",
      "        try:\n",
      "            assert(all(np.dot(P, gamma) < epsilon))\n",
      "        except AssertionError:\n",
      "            print np.dot(P, gamma)\n",
      "            raise\n",
      "        \n",
      "        return gamma\n",
      "        \n",
      "    def _vote_borda(self, neighbors, point):\n",
      "        # Compute list of distances\n",
      "        #print neighbors[0][0], point\n",
      "        dist = lambda x: np.linalg.norm(point - x)\n",
      "        distance_list = np.array([dist(i[0]) for i in neighbors])\n",
      "        max_dist = max(distance_list)\n",
      "        # Normalize it to [0,1]\n",
      "        distance_list /= max_dist\n",
      "        borda_index = [0 for i in range(self.m)]\n",
      "        for ind, neighbor in enumerate(neighbors):\n",
      "            for i in range(self.m):\n",
      "                position = neighbor[1].index(i+1)\n",
      "                borda_index[i] += (self.m - position)*self.weighting(distance_list[ind])\n",
      "        #print borda_index\n",
      "        return borda_index\n",
      "        \n",
      "    def rank(self, point, useborda=False):\n",
      "        \"\"\" Figure out the PL parameters of a point using the GMM method \"\"\"\n",
      "        # First get neighbors (including self)\n",
      "        ticret = time.time()\n",
      "        neighbors = self._get_k_nearest(self.k, point)\n",
      "        tocret = time.time() - ticret\n",
      "        #print \"Took %f seconds to get the neighbors\" % tocret\n",
      "        # Then pass neighbors (including self) into the GMM function, specifying a breaking, to get a list of parameters\n",
      "        gamma = None\n",
      "        if not useborda:\n",
      "            ticgmm = time.time()\n",
      "            gamma = self._get_GMM(neighbors, point)\n",
      "            tocgmm = time.time() - ticgmm\n",
      "            #print \"Took %f seconds to get the parameters\" % tocgmm\n",
      "            # Then sort the returned gammas (with each gamma's index corresponding to their label) to get the MAP estimate\n",
      "            try:\n",
      "                sorted_labels = [i+1 for i in sorted(range(len(gamma)), key=lambda x: -gamma[x])]\n",
      "            except ValueError:\n",
      "                print gamma\n",
      "        else:\n",
      "            borda_score = self._vote_borda(neighbors, point)\n",
      "            sorted_labels = [i[0]+1 for i in sorted(enumerate(borda_score), key=lambda x: -x[1])]\n",
      "        return sorted_labels, gamma\n",
      "    \n",
      "    def correlation(self, ranking1, ranking2):\n",
      "        return stats.kendalltau(ranking1, ranking2)\n",
      "    \n",
      "    def score(self, realX=None, realL=None, useborda=False):\n",
      "        \"\"\" Compute average kendall tau distance of training data by going through self.X, self.L \"\"\"\n",
      "        if realX == None:\n",
      "            realX = self.X\n",
      "        if realL == None:\n",
      "            realL = self.L\n",
      "        # Essentially go through each of X, L and rank\n",
      "        # Assume that realX and realL are in the same order, i.e. X[0]'s rank is L[0]\n",
      "        ktavg = 0\n",
      "        tottic = time.time()\n",
      "        for ind, instance in enumerate(realX):\n",
      "            tic = time.time()\n",
      "            #print \"Ranking instance %d\" % ind\n",
      "            predicted, gamma = self.rank(instance, useborda=useborda)\n",
      "            toc = time.time() - tic\n",
      "            #print \"Took %f seconds\" % toc\n",
      "            ktd, pv = self.correlation(predicted, realL[ind])\n",
      "            #print \"Got Kendall Tau correlation of %f\" % ktd\n",
      "            ktavg += ktd\n",
      "        tottoc = time.time() - tottic\n",
      "        ktavg /= len(realX)\n",
      "        #print \"Average Kendall Tau: %f\" % ktavg\n",
      "        #print \"Took %f seconds (%f seconds on average)\" % (tottoc, tottoc/len(realX))\n",
      "        return ktavg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 726
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reasonably_the_same(array, eps=1e-9):\n",
      "    avg = np.average(array)\n",
      "    return all((array - avg) < 1e-9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Because slices don't work\n",
      "def train_test_split(dataset, split):\n",
      "    train = []\n",
      "    test = []\n",
      "    for ind, i in enumerate(dataset):\n",
      "        if ind < split:\n",
      "            train.append(i)\n",
      "        else:\n",
      "            test.append(i)\n",
      "    return train, test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 245
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "epsilon = 1e-15\n",
      "randomized_dataset = zip(X,L)\n",
      "random.shuffle(randomized_dataset)\n",
      "train_split = int(0.1*len(X))\n",
      "train_set, test_set = train_test_split(randomized_dataset, train_split)\n",
      "test_gmm = IB_PLGMM()\n",
      "trainX, trainL = zip(*train_set)\n",
      "trainX = np.array(trainX)\n",
      "test_gmm.train(trainX, trainL)\n",
      "test_gmm.k = 10\n",
      "test_gmm.weighting = lambda x: 1-x\n",
      "testX, testL = zip(*test_set)\n",
      "#print all([test_gmm._row_in(i) for i in testX])\n",
      "test_gmm.rank(testX[0], useborda=False), testL[0]\n",
      "#test_gmm.score(realX=testX, realL=testL, useborda=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 581,
       "text": [
        "(([1, 2, 3], array([ 0.78033057,  0.61653372,  0.10473955])), [1, 2, 3])"
       ]
      }
     ],
     "prompt_number": 581
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def simple_cross_val(dataset, k, gmm):\n",
      "    # randomize dataset\n",
      "    random.shuffle(dataset)\n",
      "    n = float(len(dataset))\n",
      "    # split the dataset into k equal parts\n",
      "    ktau_scores = []\n",
      "    for i in range(k):\n",
      "        # Fancy slicing\n",
      "        test = dataset[int(i*n/k):int((i+1)*n/k)]\n",
      "        train = dataset[0:int(i*n/k)] + dataset[int((i+1)*n/k):-1]\n",
      "        # Madness with numpy arrays and zip\n",
      "        trainX, trainL = zip(*train)\n",
      "        trainX = np.array(trainX)\n",
      "        testX, testL = zip(*test)\n",
      "        testX = np.array(testX)\n",
      "        gmm.train(trainX, trainL)\n",
      "        ktscore = gmm.score(realX=testX, realL=testL, useborda=gmm.useborda)\n",
      "        ktau_scores.append(ktscore)\n",
      "        # Have fun gc...\n",
      "    return np.array(ktau_scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 612
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run(folds=10, iterations=5, dataset='LabelRankingData/wine_dense.txt', weighting=lambda x: 1, k=3):\n",
      "    X, L = interpret_rank_data(dataset)\n",
      "    useful_dataset = zip(X,L)\n",
      "    simple_gmm = IB_PLGMM(weighting=weighting, k=k)\n",
      "    simple_borda = IB_PLGMM(weighting=weighting, k=k, useborda=True)\n",
      "\n",
      "    simple_gmm_scores = np.zeros(folds)\n",
      "    simple_borda_scores = np.zeros(folds)\n",
      "    for i in range(iterations):\n",
      "        simple_gmm_scores += simple_cross_val(useful_dataset, folds, simple_gmm)\n",
      "        simple_borda_scores += simple_cross_val(useful_dataset, folds, simple_borda)\n",
      "    simple_gmm_scores /= iterations\n",
      "    simple_borda_scores /= iterations\n",
      "\n",
      "    gmm_score = np.average(simple_gmm_scores)\n",
      "    borda_score = np.average(simple_borda_scores)\n",
      "    return gmm_score, borda_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 683
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Defaults: uniform weighting, k = 3\"\n",
      "print run()\n",
      "print \"Uniform weighting, k = 5\"\n",
      "print run(k=5)\n",
      "print \"Inverse weighting (1-x), k = 3\"\n",
      "print run(weighting=lambda x: 1-x)\n",
      "print \"Inverse weighting (1-x), k = 5\"\n",
      "print run(weighting=lambda x: 1-x, k=5)\n",
      "print \"Negative exp (e^-x), k = 3\"\n",
      "print run(weighting=lambda x:np.exp(-x), k=3)\n",
      "print \"Negative exp (e^-x), k = 5\"\n",
      "print run(weighting=lambda x:np.exp(-x), k=5)\n",
      "print \"Negative log (-logx), k = 3\"\n",
      "print run(weighting=lambda x:-np.log(x+epsilon), k=3)\n",
      "print \"Negative log (-logx), k = 5\"\n",
      "print run(weighting=lambda x:-np.log(x+epsilon), k=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Defaults: uniform weighting, k = 3\n",
        "(0.3192156862745098, 0.46888888888888891)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Uniform weighting, k = 5\n",
        "(0.31851851851851848, 0.15830065359477122)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Inverse weighting (1-x), k = 3\n",
        "(0.40400871459694987, 0.90148148148148144)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Inverse weighting (1-x), k = 5\n",
        "(0.41533769063180825, 0.83054466230936819)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Negative exp (e^-x), k = 3\n",
        "(0.1904139433551198, 0.57751633986928097)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Negative exp (e^-x), k = 5\n",
        "(0.3152069716775599, 0.48588235294117643)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Negative log (-logx), k = 3\n",
        "(0.32854030501089321, 0.88984749455337686)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Negative log (-logx), k = 5\n",
        "(0.48470588235294115, 0.77999999999999992)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 684
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import product\n",
      "\n",
      "function_dict = {\n",
      "                 'identity': lambda x: 1,\n",
      "                 'inverse': lambda x: 1 - x,\n",
      "                 'invexp': lambda x: np.exp(-x),\n",
      "                 'neglog': lambda x: -np.log(1e-9+x)\n",
      "                 }\n",
      "\n",
      "test_datasets = [#'analcatdata-authorship_dense.txt',\n",
      "                 'bodyfat_dense.txt',\n",
      "                 'glass_dense.txt',\n",
      "                 'housing_dense.txt',\n",
      "                 'iris_dense.txt'\n",
      "                 'stock_dense.txt',\n",
      "                 'vehicle_dense.txt',\n",
      "                 'vowel_dense.txt',\n",
      "                 'wine_dense.txt',\n",
      "                 'wisconsin_dense.txt'\n",
      "                 ]\n",
      "test_datasets = ['LabelRankingData/' + i for i in test_datasets]\n",
      "max_k = 10\n",
      "test_ks = [i for i in range(max_k) if i % 2 != 0]\n",
      "\n",
      "weighting_funcs = ['identity', 'inverse', 'invexp', 'neglog']\n",
      "grid = product(test_datasets, test_ks, weighting_funcs)\n",
      "result_dict = {d:{k:{w:(-2, -2) for w in weighting_funcs} for k in test_ks} for d in test_datasets}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 717
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for paramset in grid:\n",
      "    print \"LOG: Dataset %s\\t k: %d\\t weighting: %s\\n\" % paramset\n",
      "    tic = time.time()\n",
      "    gmm, borda = run(dataset=paramset[0], k=paramset[1], weighting=function_dict[paramset[2]])\n",
      "    toc = time.time() - tic\n",
      "    print \"LOG: Took %f seconds: GMM\\t%f, Borda\\t%f\" % (toc, gmm, borda)\n",
      "    result_dict[paramset[0]][paramset[1]][paramset[2]] = (gmm, borda)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LOG: Dataset LabelRankingData/glass_dense.txt\t k: 9\t weighting: invexp\n",
        "\n",
        "LOG: Took 10.130509 seconds: GMM\t0.644681, Borda\t0.581605"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LOG: Dataset LabelRankingData/glass_dense.txt\t k: 9\t weighting: neglog\n",
        "\n",
        "LOG: Took 10.156502 seconds: GMM\t0.648739, Borda\t0.672462"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LOG: Dataset LabelRankingData/housing_dense.txt\t k: 1\t weighting: identity\n",
        "\n",
        "LOG: Took 39.211161 seconds: GMM\t0.117579, Borda\t0.737218"
       ]
      },
      {
       "ename": "UnboundLocalError",
       "evalue": "local variable 'sorted_labels' referenced before assignment",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-727-34a8848277b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"LOG: Dataset %s\\t k: %d\\t weighting: %s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mparamset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mgmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparamset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparamset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparamset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"LOG: Took %f seconds: GMM\\t%f, Borda\\t%f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-683-d2ca7fb28ceb>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(folds, iterations, dataset, weighting, k)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msimple_borda_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msimple_gmm_scores\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msimple_cross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0museful_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimple_gmm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0msimple_borda_scores\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msimple_cross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0museful_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimple_borda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msimple_gmm_scores\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-612-2b08f4c2a296>\u001b[0m in \u001b[0;36msimple_cross_val\u001b[0;34m(dataset, k, gmm)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtestX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mgmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mktscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrealX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museborda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0museborda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mktau_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mktscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Have fun gc...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-726-97505e1d335a>\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, realX, realL, useborda)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;31m#print \"Ranking instance %d\" % ind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museborda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0museborda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m             \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;31m#print \"Took %f seconds\" % toc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-726-97505e1d335a>\u001b[0m in \u001b[0;36mrank\u001b[0;34m(self, point, useborda)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mborda_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vote_borda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0msorted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mborda_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msorted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcorrelation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranking1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranking2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'sorted_labels' referenced before assignment"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LOG: Dataset LabelRankingData/housing_dense.txt\t k: 1\t weighting: inverse\n",
        "\n",
        "[[ 1.  0.  0.  0.  0.  0.]\n",
        " [ 0.  1.  0.  0.  0.  0.]\n",
        " [ 0.  0.  1.  0.  0.  0.]\n",
        " [ 0.  0.  0.  1.  0.  0.]\n",
        " [ 0.  0.  0.  0.  1.  0.]\n",
        " [ 0.  0.  0.  0.  0.  1.]]\n"
       ]
      }
     ],
     "prompt_number": 727
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.array([[-2., 1/3., 1/3., 1/3.],[2/3., -4/3., 1/3., 2/3.], [2/3., 2/3., -1., 2/3.], [2/3., 1/3., 1/3., -5/3.]])\n",
      "print np.sum(A, axis=0)\n",
      "print np.linalg.matrix_rank(A)\n",
      "print A"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ -1.11022302e-16   0.00000000e+00  -5.55111512e-17  -1.66533454e-16]\n",
        "3\n",
        "[[-2.          0.33333333  0.33333333  0.33333333]\n",
        " [ 0.66666667 -1.33333333  0.33333333  0.66666667]\n",
        " [ 0.66666667  0.66666667 -1.          0.66666667]\n",
        " [ 0.66666667  0.33333333  0.33333333 -1.66666667]]\n"
       ]
      }
     ],
     "prompt_number": 711
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "B = np.array([[-1.54320865,  0.41158825,  0.12262648,  0.63702937,  0.41158825,  0.3480676,\n",
      "   0.3480676 ],\n",
      " [ 0.22544112, -2.30727931,  0.12262648,  0.3480676,   0.12262648,  0.3480676,\n",
      "   0.3480676 ],\n",
      " [ 0.51440288,  0.51440288, -0.75965585,  0.63702937,  0.41158825,  0.3480676,\n",
      "   0.63702937],\n",
      " [ 0.,          0.28896176,  0.,         -2.71445275,  0.12262648,  0.3480676,\n",
      "   0.3480676 ],\n",
      " [ 0.22544112,  0.51440288,  0.22544112,  0.51440288, -1.64635298,  0.3480676,\n",
      "   0.3480676 ],\n",
      " [ 0.28896176,  0.28896176,  0.28896176,  0.28896176,  0.28896176, -1.86296448,\n",
      "   0.51440288],\n",
      " [ 0.28896176,  0.28896176,  0.,          0.28896176,  0.28896176,  0.12262648,\n",
      "  -2.54370265]])\n",
      "\n",
      "print np.linalg.matrix_rank(B)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7\n"
       ]
      }
     ],
     "prompt_number": 715
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dicks = IB_PLGMM()\n",
      "dicks.m = 4\n",
      "dicks.weighting = lambda x: 1\n",
      "neighbors = [(np.array([1]),[1,2,3,4]),(np.array([2]),[4,3,2,1]), (np.array([3]),[3,2,4,1])]\n",
      "dicks._get_GMM(neighbors, np.array([1]))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[-2.          0.33333333  0.33333333  0.33333333]\n",
        " [ 0.66666667 -1.33333333  0.33333333  0.66666667]\n",
        " [ 0.66666667  0.66666667 -1.          0.66666667]\n",
        " [ 0.66666667  0.33333333  0.33333333 -1.66666667]]\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 710,
       "text": [
        "array([ 0.26629084,  0.49707623,  0.74561434,  0.35505445])"
       ]
      }
     ],
     "prompt_number": 710
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class GMMError(Exception):\n",
      "    def __init__(self, issue, reproduce):\n",
      "        self.issue = issue\n",
      "        self.reproduce = reproduce\n",
      "import cPickle as pickle\n",
      "pickle.load(open('results.dat','r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "('__init__() takes exactly 3 arguments (1 given)', <class '__main__.GMMError'>, ())",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-729-06a170c5a307>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreproduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreproduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcPickle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results.dat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mTypeError\u001b[0m: ('__init__() takes exactly 3 arguments (1 given)', <class '__main__.GMMError'>, ())"
       ]
      }
     ],
     "prompt_number": 729
    }
   ],
   "metadata": {}
  }
 ]
}